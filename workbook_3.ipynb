{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "import pyinflect\n",
    "import spacy\n",
    "import re\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subject_plural(token):\n",
    "    subjs = [t for t in token.lefts if 'subj' in t.dep_]\n",
    "    # nouns = [t for t in token.lefts if 'NOUN' in t.dep_]\n",
    "    nouns = [t for t in token.sent[:token.i] if 'NOUN' in t.pos_]\n",
    "    if len(subjs) > 0 :\n",
    "        # print(\"Subject found\")\n",
    "        # print(subjs)\n",
    "        morph = subjs[0].morph.to_dict()\n",
    "        if 'Number' in morph.keys():\n",
    "            return morph['Number']\n",
    "        elif 'S' in subjs[0].tag_:\n",
    "            return 'Plur'\n",
    "        else:\n",
    "            return 'Sing'\n",
    "            \n",
    "            \n",
    "    elif len(nouns) > 0 :\n",
    "        # print(\"Nouns found\")\n",
    "        # print(nouns)\n",
    "        morph = nouns[0].morph.to_dict()\n",
    "        if 'Number' in morph.keys():\n",
    "            return morph['Number']\n",
    "        elif 'S' in nouns[0].tag_:\n",
    "            return 'Plur'\n",
    "        else:\n",
    "            return 'Sing'\n",
    "    \n",
    "    else:\n",
    "        return 'Sing'\n",
    "\n",
    "        \n",
    "def sentence_past_tense(txt, nlp):\n",
    "    doc = nlp(txt)\n",
    "    out = list()\n",
    "    words = []\n",
    "    aux_count = 0\n",
    "    aux_phrase = []\n",
    "\n",
    "    \n",
    "    for word in doc:\n",
    "        words.append(word)\n",
    "\n",
    "        tag = word.tag_\n",
    "        pos = word.pos_\n",
    "        dep = word.dep_\n",
    "\n",
    "        \n",
    "        if 'AUX' in pos and dep != 'ROOT':\n",
    "            aux_count = aux_count +1\n",
    "            aux_phrase.append(word.lemma_)\n",
    "            \n",
    "        else:  \n",
    "            if dep == \"ROOT\" or 'cl' in dep:\n",
    "                print(\"Root:\"+ word.text)\n",
    "                print(aux_phrase)\n",
    "                if (('be' in aux_phrase) or ('am' in aux_phrase) ) and aux_count > 1:\n",
    "                    \n",
    "                    plural = find_subject_plural(word)\n",
    "                    print(word.sent[word.i-2])\n",
    "                    if 'RB' in word.sent[word.i-2].tag_:\n",
    "\n",
    "                        print('ADVERBBBB')\n",
    "                        if plural == 'Sing':\n",
    "                            out.insert(word.i-1, 'was')\n",
    "                        else:\n",
    "                            out.insert(word.i-1, 'were')\n",
    "                    else:\n",
    "                        # print(plural)\n",
    "                        print('not adverb')\n",
    "                        if plural == 'Sing':\n",
    "                            out.append('was')\n",
    "                        else:\n",
    "                            out.append('were')\n",
    "                    \n",
    "                    aux_count = 0\n",
    "                    aux_phrase = []\n",
    "                elif (('be' in aux_phrase) or ('am' in aux_phrase) ) and word.tag_ == 'VBN':\n",
    "                    # print('huh')\n",
    "                    plural = find_subject_plural(word)\n",
    "                    # print(plural)\n",
    "                    if plural == 'Sing':\n",
    "                        out.append('was')\n",
    "                    else:\n",
    "                        out.append('were')\n",
    "                    aux_count = 0\n",
    "                    aux_phrase = []\n",
    "\n",
    "                if tag in ['VBN', 'VBP', 'VBZ']:\n",
    "                    plural = find_subject_plural(word)\n",
    "                    print(word.text +' verb conjugation')\n",
    "                    if plural == 'Sing':\n",
    "                        new_word = word._.inflect('VBD', form_num = 0)\n",
    "                    else:\n",
    "                        new_word = word._.inflect('VBD', form_num = 1) \n",
    "                else:\n",
    "                    new_word = None\n",
    "                \n",
    "\n",
    "                if new_word is not None:\n",
    "                    out.append(new_word)\n",
    "                else:\n",
    "                    out.append(word.text)\n",
    "                aux_count = 0\n",
    "                aux_phrase = []\n",
    "            \n",
    "            else:\n",
    "                out.append(word.text)\n",
    "    \n",
    "    # print(out)\n",
    "    if len(out) > 0:\n",
    "        out = \" \".join(out)\n",
    "            \n",
    "    return out\n",
    "    \n",
    "  \n",
    "\n",
    "def tense_correct_para(txt):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    delimiters = r'[.:;\\t]'\n",
    "    chunks = re.split(delimiters, txt)\n",
    "    for c in chunks:\n",
    "        new_chunk = sentence_past_tense(c, nlp)\n",
    "        print(c)\n",
    "        if len(new_chunk) > 0:\n",
    "            # print(new_chunk)\n",
    "            txt = txt.replace(c, new_chunk)\n",
    "    \n",
    "\n",
    "    return txt\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "# will aux - drop\n",
    "# will be aux - was/were\n",
    "# will have - drop\n",
    "# are going to - drop\n",
    "# are - drop\n",
    "        \n",
    "# accounts can be updated - accounts were updated\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"•\tBlinding of Study: The study will not be blinded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root:•\n",
      "[]\n",
      "•\n",
      "Root:Blinding\n",
      "[]\n",
      "Blinding of Study\n",
      "Root:blinded\n",
      "['will', 'be']\n",
      "Nouns found\n",
      "[study]\n",
      "be\n",
      "not adverb\n",
      "Nouns found\n",
      "[study]\n",
      "blinded verb conjugation\n",
      " The study will not be blinded\n"
     ]
    }
   ],
   "source": [
    "txt2 = tense_correct_para(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nlp(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(a) for a in test[-1].children if 'RB' in a.tag_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nlp(\"For n=5 per group, brains will be dissected out, split into left and right hemispheres, placed in individual cryovials, and then frozen in isopentane pre-chilled on dry ice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nlp('Here, we have a sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [\" \"+token.text if token.pos_ != 'PUNCT' else token.text for token in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subject_plural(token):\n",
    "    # subjs = [t for t in token.ancestors if 'subj' in t.dep_]\n",
    "    subjs = [t for t in token.lefts if 'subj' in t.dep_]\n",
    "    # nouns = [t for t in token.lefts if 'NOUN' in t.dep_]\n",
    "    nouns = [t for t in token.sent[:token.i] if 'NOUN' in t.pos_]\n",
    "    if subjs:\n",
    "\n",
    "        # print(subjs[0])\n",
    "        morph = subjs[0].morph.to_dict()\n",
    "        if 'Number' in morph.keys():\n",
    "            return morph['Number']\n",
    "        elif 'S' in subjs[0].tag_:\n",
    "            return 'Plur'\n",
    "        else:\n",
    "            return 'Sing'\n",
    "            \n",
    "            \n",
    "    elif nouns:\n",
    "        # print(nouns[0])\n",
    "        morph = nouns[-1].morph.to_dict()\n",
    "        if 'Number' in morph.keys():\n",
    "            return morph['Number']\n",
    "        elif 'S' in nouns[-1].tag_:\n",
    "            return 'Plur'\n",
    "        else:\n",
    "            return 'Sing'\n",
    "    \n",
    "    else:\n",
    "        return 'Sing'\n",
    "\n",
    "def past_tensify(txt, nlp):\n",
    "    doc = nlp(txt)\n",
    "    out = list()\n",
    "    words = []\n",
    "    aux_count = 0\n",
    "    aux_phrase = []\n",
    "\n",
    "    for word in doc:\n",
    "        words.append(word)\n",
    "        new_word = None\n",
    "        tag = word.tag_\n",
    "        pos = word.pos_\n",
    "        dep = word.dep_\n",
    "\n",
    "        if 'AUX' in pos and dep != 'ROOT' and out[-1].lower() != 'to':# and word.text != 'is':\n",
    "            aux_count = aux_count +1\n",
    "            aux_phrase.append(word.lemma_)\n",
    "\n",
    "            # remove auxillary words, but keep track of recent removals. \n",
    "            # Do not remove auxillary words that are roots (i.e. be as the root verb)\n",
    "            # Do not remove auxillary words following 'to'\n",
    "            \n",
    "        else:  \n",
    "            if (dep == \"ROOT\") or ('cl' in dep) or ('conj' in dep) :\n",
    "\n",
    "                if dep == 'ROOT':\n",
    "                    print(\"ROOT: \"+word.text)\n",
    "                \n",
    "                if 'cl' in dep:\n",
    "                    print(\"cl: \"+word.text)\n",
    "\n",
    "                if 'conj' in dep:\n",
    "                    print('conj: '+word.text)\n",
    "                \n",
    "                # determine if the subject is plural or singular\n",
    "                plural = find_subject_plural(word)\n",
    "\n",
    "                # pull out any adverbs\n",
    "                adverbs = [a for a in word.children if 'RB' in a.tag_]\n",
    "\n",
    "                # Identify 'be' in auxillary clause (will be, have been) to replace with was/were\n",
    "                # or Identify 'be' in conjuction with past participle (are having, am walking) to replace with was/were\n",
    "                if ((('be' in aux_phrase) or ('am' in aux_phrase) ) and aux_count > 1) or \\\n",
    "                    ((('be' in aux_phrase) or ('am' in aux_phrase) ) and word.tag_ in ['VBN', 'VBG']): \n",
    "                    print('AUX lemmas \\t')\n",
    "                    print(aux_phrase)\n",
    "\n",
    "                    if word.tag_ != 'VBG':\n",
    "                        if plural == 'Sing':\n",
    "                            out.append('was')\n",
    "                        else:\n",
    "                            out.append('were')\n",
    "                    else:\n",
    "                        new_word = word._.inflect('VBD', form_num = 0)\n",
    "                \n",
    "                    aux_count = 0\n",
    "                    aux_phrase = []\n",
    "\n",
    "                if (tag in ['VB', 'VBP']) and ( word.text.lower() != 'see') and (out[-1].lower() != 'to'): # removed VBN and VBZ in wild test # \n",
    "\n",
    "                    if word.lemma_ == 'be':\n",
    "                        print('be lemma')\n",
    "                        if plural == 'Sing':\n",
    "                            \n",
    "                            new_word = 'was'\n",
    "                        else:\n",
    "                            \n",
    "                            new_word = 'were'\n",
    "                    else:      \n",
    "                        if plural == 'Sing':\n",
    "                            new_word = word._.inflect('VBD', form_num = 0)\n",
    "\n",
    "                            print('Inflection: '+ new_word)\n",
    "                        else:\n",
    "                            new_word = word._.inflect('VBD', form_num = 1)\n",
    "                            print('Inflection: '+ new_word)\n",
    "\n",
    "                elif new_word is None:\n",
    "                    new_word = word.text\n",
    "                \n",
    "                for adv in adverbs:\n",
    "                    print(\"ADVERB: \"+adv.text)\n",
    "                    if adv.text in out and adv.i in range(word.i - (len(adverbs)+1), word.i + (len(adverbs)+1)):\n",
    "                        \n",
    "                        out.pop(out.index(adv.text))\n",
    "                        out.append(adv.text)\n",
    "\n",
    "                if new_word is not None:\n",
    "                    out.append(new_word)\n",
    "                else:\n",
    "                    out.append(word.text)\n",
    "                \n",
    "                aux_count = 0\n",
    "                aux_phrase = []\n",
    "            \n",
    "            else:\n",
    "                out.append(word.text)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    # print(out)\n",
    "    if len(out) > 0:\n",
    "        out = \" \".join(out)\n",
    "\n",
    "    return out     \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [\n",
    "    \"The stimulus will automatically shut off when the animal withdraws its paw and the latency to the withdrawal will be recorded, with a cutoff of 20 s employed to prevent tissue damage. \",\n",
    "    \"Here we are providing a formal proposal for a study involving 3 treatment groups.\",\n",
    "    \"A small pilot dose response study to harmaline will be conducted in CD-1 mice to determine the dose of harmaline to be used in the main study.\",\n",
    "    \"The heat stimulus will be adjusted prior to the experiment so as to obtain approximately 10 second baseline responses in control rats. \",\n",
    "    \"Body weight will be monitored daily and clinical score will be measured daily beginning at day 7 after immunization and ending on day 30.\",\n",
    "    \"Mice at this stage are given food on the cage floor, long sipper tubes, and daily subcutaneous saline injections to prevent death by dehydration.\",\n",
    "    \"*Note: EAE is cyclical, so about 21 days after immunization, some animals may begin to return to normal “0”. They will then begin the next cycle.\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = [\"Once the rats remain still, a radiant heat source will be moved beneath the portion of the ipsilateral paw that is flush with the glass. \",\n",
    "        \"IM injection volume will be 20 µl (=1 µg) per injections site into each of the left and right caudal thigh muscle. \",\n",
    "        \"The imaging time will be 1 min post- D-Luciferin injection. \"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: be\n",
      "be lemma\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The imaging time was 1 min post- D - Luciferin injection .'"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_tensify(errs[-1],nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nlp(errs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VB'"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[4].tag_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nlp(chunks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[2].lemma_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
